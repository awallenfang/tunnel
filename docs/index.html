<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Tunnel Dokumentation</title>
</head>
<body>
    <main>
        <section class="section">
            <h1>Tunnel Dokumentation</h1>
            <p>Das Prinzip dieses Projektes ist es zu experimentieren was alles mittels impliziter Grafik möglich ist und wo gegebenenfalls auch Schwierigkeiten im Vergleich zu expliziter Darstellung liegen.</p>
            <p>Dazu hat jeweils jede Person einen Tunnel in einem Shader implizit definiert und darauf verschiedene Effekte, wie Pathtracing und Ambient Occlusion implementiert, welche dann hintereinander gerendert werden.</p>
            <p>Die drei enstandenen Tunnel sind:
                <ul>
                    <li>
                        Ein Voxel basierter Tunnel, um mit Voxel Umformungen zu experimentieren
                    </li>
                    <li>
                        Ein Rohr um mit Echtzeiteffekten wie Ambient Occlusion und Shadow Mapping zu experimentieren
                    </li>
                    <li>
                        Eine Höhle um mit Lichtinteraktionen durch Pathtracing zu experimentieren
                    </li>
                </ul>
            </p>

            <p>
                Alle Tunnel wurden mittels Ray-Marching implementiert, wobei eine <abbr title="Signed Distance Function">SDF</abbr> definiert wird, welche zu eine Inputposition den Abstand zu der nächsten Position der Umgebung zurückgibt. <br> 
                Damit werden dann Strahlen in die Szene geschossen, bei denen jeweils die Entfernung der <abbr title="Signed Distance Function">SDF</abbr> nach vorne geschritten wird, bis ein Threshold erreicht wird. Zurückgegeben wird dann die insgesamt zurückgelegte Entfernung.
            </p>

            <h2>Rendering</h2>
            <p>
                Jeder Tunnel befindet sich in einer eigenen Shader Datei, die getrennt voneinander mittels tunnel.cpp gerendert werden. 
                Um einen Tunnel auszuwählen wird die Environment Variabel "SHADER_OVERWRITE" genutzt. Die drei Tunnelnamen sind "tunnel_gem.frag", "tunnel_industrial.frag" und "voxel_trace.frag". <br>
                Der Voxel Tunnel wird also mit "SHADER_OVERWRITE=voxel_trace.frag ./tunnel" ausgeführt. <br><br>
                Um die gerenderten Frames auch abzuspeichern muss die Variabel "SCREEN_DUMP" gesetzt werden. Um den Voxel-Tunnel zu rendern ist also der Befehl "SCREEN_DUMP=TRUE SHADER_OVERWRITE=voxel_trace.frag ./tunnel" nötig.
            </p>

            <p>
                Wichtig ist, dass bei dem Rendern von "tunnel_gem" intern noch die Sampleanzahl von 1 auf die gewünschte Samplemenge erhöht werden muss.
            </p>
        </section>
        <section class="section">
            <h2>Voxel Tunnel</h2>
            <section class="subsection">
                <h3>Was ist ein Voxel?</h3>
                <p>Ein Voxel kann man sich als 3D Äquivalent eines Pixels vorstellen.
                    Dabei wird der Raum in ein Raster aufgeteilt wo jeder Punkt im Raum zu genau einer Zelle in dem Gitter zugeordnet ist.
                    Beim rendern wird dies oft durch eine Blockwelt repräsentiert wie zu Beispiel bei Minecraft.</p>
            </section>
            <section class="subsection">
                <h3>Voxel durch impliziertes Rendern darstellen.</h3>
                <p>Da wir in unserem Projekt das implizierte Rendern gewählt haben mussten wir eine Möglichkeit Voxel dort darzustellen.</p>
                <h3>1. Die Map Funktion</h3>
                <p>Unser erster Ansatz war die Voxel durch eine Map funktion zu repräsentieren. Dabei wird die Position auf das Raster übertragen. Falls dieser Voxel gefüllt ist wird ein Treffer registriert und eine negative Distanz innerhalb des Voxels zurückgegeben falls kein Treffer registiert wird muss die größte Distanz innerhalb des Voxels berechnet werden und dies ist dann die Distanz der sdf.</p>
                <h4>Vorteile</h4>
                <ul>
                    <li>Sehr einfach in bestehende Renderer einzubauen</li>
                    <li>Kann leicht mit einer nicht Voxel welt verbunden werden</li>
                </ul>
                <h4>Nachteile</h4>
                <ul>
                    <li>Distanzen zu berechnen ist anstrengend da auch die Diagonalen Nachbarn betrachtet werden müssten</li>
                </ul>
            </section>
            <section class="subsection">
                <h3>2. Die Trace Funktion</h3>
                <p>Hierbei bewegen wir uns mit der Trace Funktion selber nur in größe der Voxel durch den Raum und nutzt eine jegliche Standart Map Funktion.</p>
                <h4>Vorteile</h4>
                <ul>
                    <li>Kann in Verbindung mit jeglicher Map Funktion benutzt werden, es muss keine Welt in Voxel erzeugt werden</li>
                </ul>
                <h4>Nachteile</h4>
                <ul>
                    <li>Der Renderer selber muss verändert werden</li>
                </ul>
            </section>
            <section>
                <h3>Unser Ansatz:</h3>
                <p>Wir haben Angefangen mit dem ersten Ansatz die Versuche sind leider erfolglos geblieben die nachfolgenden Bilder sind beispiele.</p>
                <img src="images/voxel_1.png" alt="" width="50%" class="screen-dump">
                <img src="images/voxel_2.png" alt="" width="50%" class="screen-dump">
                <img src="images/voxel_5.png" alt="" width="50%" class="screen-dump">

                <p>Danach haben wir den Ansatz 2 gewählt da dieser die Möglichkeit für standart Map funktion liefert und leichter umzusetzten ist.</p>
                <img src="images/voxel_6.png" class="screen-dump" title="Eine frühere Version des Höhlen Tunnels voxeliert dargestellt" width="50%">
                <img src="images/voxel_14.png" class="screen-dump" title="Der erste Voxel Tunnel ohne jegliche extras" width="50%">

                <p>Ein Vorteil an diesem Ansatz ist ebenfalls das Voxelgrößen sehr einfach anpassbar sind da der Tracer sehr einfach die Schrittgröße anpassen kann und somit sich auf die Voxelgröße verändert.</p>
            </section>
            <section class="subsection">
                <h3>Wasser</h3>
                <p>Die erste Idee des Wassers waren kleine teiche am boden des Tunnels</p>
                <img src="images/voxel_7.png" class="screen-dump" alt="" width="50%">
                <p>Jedoch wirkte Wasserbewegung dabei unrealistisch statisch Wasser wäre jedoch sehr langweilig gewesen, daher sind wir darauf gekommen das Wasser in einen Fluss zu verwandeln.</p>
                <img src="images/voxel_8.png" class="screen-dump" alt="">
            </section>
            <section class="subsection">
                <h3>Das Boot</h3>
                <p>Die erste Idee war hier das Boot als einfache Geometrie in die Szene miteinzufügen das hat jedoch zu Problemen geführt. Das Boot ist hierbei eine hohle Halbkugel.</p>
                <img src="voxel_boot_schlecht.png" class="screen-dump" alt="" width="50%">
                <p>Das Erste Problem das auffällt ist Tatsache das das Boot unter Wasser ist, dieses Problem ließe sich leicht beheben jedoch gab es ein größeres Problem.</p>
                <p> Das Boot bewegt sich sehr rucklig durch den Raum. Dies ist auch keine Überraschung da das Boot eine Mathematisch beschriebene Halbkugel ist und sobald sich diese durch den diskreten Raum bewegt sie automatisch anfängt sich blockig zu bewegen.</p>
                <p>Den Ansatz den wir also stattdessen gewählt haben ist sehr ähnlich auch in vielen Spielen aus der first-person perspektive zu finden. Dabei werden die Hände oft seperat gerendert und dann über alles andere drüber gelegt damit die Hände nicht in naher Geometrie verschwinden. Hier wird das Boot durch einen weiteren Aufruf der Map Funktion gerendert, falls also bei diesem Aufruf das Boot getroffen wird nehmen wir das Boot als Farbe und ansonsten nutzen wir die normale Szene. </p>
                <img src="images/voxel_9.png" class="screen-dump" alt="">
                <p>Jetzt stellt sich natürlich noch die Frage wie sich das Schwanken des Boots umsetzten lässt. Das rotieren der Halbkugel verändert nichts, da diese exakt die selbe Halbkugel rundherum ist habenn wir den Ansatz gewählt den Strahl den wir auf das Boot schießen zu rotieren.</p>
                <p>Für das auf und abschwanken haben wir die blickrichtung der generellen Szene verändert da so das gesamte Blickfeld sich auf und ab bewegt.</p>
            </section>
        </section>
        </section>
        <section class="section">
            <h2>Rohr</h2>
            <section class="subsection">
                <h3>Modellierung</h3>
                <p>
                    Das Ziel dieser Szene war es ein möglichst realistisches Rohr zu modellieren.
                    Das Modell ist dabei an ein mögliches Fertigungsverfahren angelehnt:<br>
                    Zuerst werden drei Rohrbögen, welche jeweils ein Drittel eines Kreises abdecken verschweißt und bilden somit einzelne Rohrstücke.
                    Diese Rohrstücke werden dann wiederrum mittels Bolzen untereinander befestigt. Um die Stabilität des Tunnels
                    zu verbessern werden weiterhin die Rohrstücke um ein Sechstel versetzt aneinander gereiht.
                </p>
                <h4>Technische Umsetzung des Modells</h4>
                <p>
                    Um nun diese wiederkehrenden Merkmale auf dem Kreis in der x-y-Ebene zu konstruieren, wird zuerst berechnet in welchem Kreisstück sich der Ausgangspunkt befindet.
                    Danach werden die x- und y-Koordinaten des Ausgangspunktes um den Winkel des davor bestimmten Kreisbogens rotiert. Für ein dreigeteilten Kreis bleibt somit ein Punkt welcher einen Winkel 0 hatte bestehen und
                    die Punkte mit dem Winkel 120° und 240° werden so rotiert, dass der neue Winkel 0 ist. Diese rotierte Punkte bieten jetzt die Möglichkeit mit einfachen bekannten SDFs (bspw. Quader, Würfel, usw.)
                    kreisförmig wiederholende Merkmale zu modellieren. <br><br>
                </p>
                <p>
                    <img src="images/pipe_1.jpg">
                    <br>
                    <small>Exemplarische Darstellung der Rotation für Bogenstücke der Größe 120° (Drittelstücke)</small>
                </p>
                <p>
                    Auch die Versetzung je Rohrstück lässt sich mit dieser Methode leicht modellieren, so wird der Winkel, um den zuvor rotiert wurde, abhängig von der z-Koordinate wiederkehrend erhöht bzw. verringert.
                    Damit sind die Punkte welche einen Winkel 0 auf dem Kreis haben nun um einen weiteren Winkel verschoben (hier 60° oder 1/6 Kreis) verschoben.
                </p>
                <img src="images/pipe_2.png" class="screen-dump">
            </section>
            <section class="subsection">
                <h3>Zusätzliche Effekte & Verfahren</h3>
                <h4>Tunnel Pfad</h4>
                <p>
                    Damit das Rohr nicht endlos in z-Richtung wächst wird sowohl der Beobachter als auch die Szene mittels einer Pfadfunktion verschoben.
                    Diese ist der Einfachheit halber eine von der z-Koordinate abhängig sin und cos Translation der x und y Koordinate. Bei einer höheren Geschwindigkeit ist somit auch eine Periode erkennbar,
                    für kürzere Rendering des Tunnels ist das allerdings nicht störend
                </p>
                <img src="images/pipe_3.png" class="screen-dump">
                <h4>Soft-shadows & Ambient Occlusion</h4>
                <p>
                    Für die Szene wurden weiterhin Soft Shadows und Ambient Occlusion benutzt. Die Implementierung dieser, falls die Szene in SDFs vorliegt ist erstaunlich unkompliziert.<br>
                    Für Ambient Occlusion wird ausgehenden von dem zu rendernden Punktes in Normalen-Richtung wenige Punkte mit geringem Abstand abgegangen und je Punkt wird der Abstand zu Szene bestimmt.
                    Je höher die Differenz des gegangenen Weges und der Abstand zu Szene ist, desto mehr sollte der zu rendernde Punkt verdeckt werden. <br>
                    Auch Soft-Shadows lassen sich erstaunlich leicht rendern:
                    Hierfür wird ausgehend des zu rendernden Punktes zur Lichtquelle gemarched. Dabei wird das Minimum eines berechneten Schattens gesammelt (skaliert mit dem bereits gegangen Weges)
                    und als Faktor auf die zu rendernde Farbe aufmultipliziert.
                </p>
                <img src="images/pipe_4.png" class="screen-dump">
                <h4>Materialien</h4>
                <p>
                    Um der Szene noch ein wenig Abwechslung zu verpassen existieren nun zwei Materialien. Ein rotes (rostiges) Metall des Rohres und ein wenig silbernes Metall für die Bolzen.
                </p>
                <img src="images/pipe_5.png" class="screen-dump">
                <h4>Bump Mapping</h4>
                <p>
                    Die beiden Materialien haben nun zwar interessantere Farben doch ist beides für Metall recht glatt. Abhilfe dafür sollte das Normal Bump Mapping schaffen.
                    Dabei wird die Normale in diesem Fall abhängig von der Position pseudo zufällig verändert. Dafür wurde eine Funktion definiert, welche die Bump Map repräsentiert.
                    Für diese Funktion wird der Gradient numerisch bestimmt. Danach wird die Normale mit dem Skalarprodukt zwischen Normale und Gradient skaliert.
                    Außerdem ist auf die anschließende Normalisierung der Normale zu achten.
                </p>
                <img src="images/pipe_6.png" class="screen-dump">
                <h4>Texturen und textur basiertes Bump Mapping</h4>
                <p>
                    Um der Szene einen abschließenden Schliff zu verpassen sollte weiterhin die beiden Materialien eine Textur bekommen.
                    Mittels dieser Textur wird daraufhin ein weiteres Bump Mapping berechnet.
                    Dieses unterscheidet sich im Prinzip nicht von dem davor genannten Bump Mapping. Die Besonderheit hierbei ist es jedoch ein rgb-Bild als Bump Map zu verwenden.
                    Dafür wird der gegebene Texturwert in Grayscale umgerechnet und danach als Bump Map Funktion benutzt.
                </p>
                <img src="images/pipe_7.png" class="screen-dump">
            </section>
        </section>
        <section class="section">
            <h2>Höhle</h2>
            <section class="subsection">
                <h3>Vorab Bekannte Schwierigkeiten</h3>
                <p>
                    Ziel war es einen Pathtracer zu implementieren, durch den verschieden-farbige Lampen an den Wänden Licht an alle Stellen der Höhle strahlen können. <br>
                    Bevor überhaupt begonnen wurde war bereits klar, dass es unmöglich sein wird dies in Echtzeit umzusetzen, geschweige denn in kurzer Zeit zu rendern. 
                    Im Laufe der Arbeitszeit war die Überlegung das Pathtracing-System auch auf die anderen beiden Tunnel anzuwenden, was, aber den zeitlichen Rahmen für das Rendern sprengen würde. <br>
                    Dadurch ist das nun implementierte System aber sehr abgeschlossen und kann ohne viel Arbeit in ein weiteren Shader mit Ray-Marching übernommen werden.
                </p>

                <p>
                    Dabei war ebenfalls klar, dass man sich in einem Tunnel befindet und somit kein Sonnenlicht existiert. 
                    Dies hat zur Folge, dass ein Großteil der Strahlen bei simplem Pathtracing ins leere schießen und somit nicht zum Licht beitragen.
                </p>
            </section>
            <section class="subsection">
                <h3>Umgebungsdefinition</h3>
                <p>
                    Begonnen wurde erstmal damit simple Formen und Operationen, wie Würfel und Rotationen zu definieren. <br>
                    Besonders bei der Rotation entstanden bereits einige komische Fehler, wie dass das rotierte Objekt abgeschnitten wird.
                </p>
                <img src="images/gem_1.png">
                <p>
                    Sobald alle Grundoperationen korrekt implementiert wurden war es relativ simpel den Rest der Grundszene zu bauen.
                </p>
                <p>
                    An dieser Stelle wird auf die <abbr title="Signed Distance Function">SDF</abbr> einfach eine Noise-Textur addiert, wodurch die rauhe Darstellung entsteht. Dies lädt aber auch diverses Experimentieren mit anderen Funktionen ein, wie modulierten sinus-Kurven.
                </p>
                <div class="video-block">
                    <video width="40%" controls>
                        <source src="images/gem_2.mp4" type="video/mp4">
                    </video>
                    <video width="40%" controls>
                        <source src="images/gem_3.mp4" type="video/mp4">
                    </video>
                </div>
                
                <p>
                    Bei den stärkeren Noise-Operationen wird aber auch bereits eine schwäche von Ray-Marching offengelegt. Eine Addition auf Distantfunktionen resultiert nämlich nicht in einer weiteren korrekten Distanzfunktion, weswegen sich in diesem Fall die schwarzen Stellen entwickeln. <br>
                    An diesen Stellen springt der Strahl wegen den falschen Distanzfunktionen zu weit und trifft das korrekte Ziel somit nicht. 
                </p>

                <p>
                    Es existiert aber auch eine Lösung zu diesem Problem, welche aber um einiges mehr Rechenzeit benötigt. 
                    Dabei werden iterativ immer kleiner werdende Objekte an der Wand platziert und mit dieser verbunden. 
                    Dadurch entsteht eine rauhe Darstellung, ohne, dass die <abbr title="Signed Distance Function">SDF</abbr> falsch wird.
                </p>

                <img src="images/gem_4.png">

                <p>
                    Der nächste Schritt ist es eine Möglichkeit zu haben um aus der Distanzfunktion auch Materialinformationen zu erhalten. Um dies zu erreichen wird aus jeder <abbr title="Signed Distance Function">SDF</abbr> nun anstelle einer Distanz, ein "Object" zurückgegeben, welches die Distanzinformationen, sowie Materialinfos beinhält. <br>
                    Diese können dann bei dem Rendering genutzt werden.
                </p>

                <p>
                    Der letzte Schritt ist es nun die Lampenpositionen zu definieren. Anfänglich waren diese statisch auch in dem Shader definiert, aber dies ist sehr unhandlich, da wegen dem Fehlen eines Sonnenlichtes sehr viele Lampen nötig sind. <br>
                    Deswegen wurden diese außerhalb in c++ generiert und dann mit Uniforms in den Shader eingebunden. Die <abbr title="Signed Distance Function">SDF</abbr> für die Lampen iteriert über alle Lampen und gibt die mit der kleinsten Entfernung am Ende aus.
                </p>
            </section>

            <section class="subsection">
                <h3>Rendering</h3>
                <p>
                    Anfänglich wurden zum Testen von der Umgebung die Schatten direkt basierend auf Punktlichtquellen implementiert, was aber schnell auch mit dem neuen Pathtracer ersetzt wurde. <br>
                    Dabei entstanden aber auch bereits Probleme mit falschen <abbr title="Signed Distance Function">SDF</abbr>-Werten, wodurch Schatten falsche berechnet wurden. <br> 
                </p>

                <img src="images/gem_5.png">

                <p>
                    Der Pathtracer ist ein simpler cosine-weighted Pathtracer, da es zeitlich leider nicht möglich war, weitere schnellere Gewichtungen erfolgreich zu implementieren. <br>
                    Die größte Schwierigkeit dabei war es den Code korrekt zu implementieren, sodass der PC bei dem Ausführen nicht wegen der großen Last im Shader abstürzt und den folgenden Output generiert.
                </p>

                <img src="images/gem_6.png" class="screen-dump">

                <p>
                    Dies wurde gelöst, indem pro Shader-Durchlauf nur ein einziger Sample berechnet wird und diese Outputs dann mithilfe des Alpha-Kanals in OpenGL addiert werden, bis das vollständige Bild gerendert wurde. <br>
                    Bei dem setzen des Alpha-Wertes wird noch die Stärke der Farben insgesamt erhöht, indem Alpha nicht auf 1/samples gesetzt wird, sondern nur auf 1/5, da ein großteil der Samples schwarz sind. Dadurch wird zwar teilweise Realismus verloren, aber die Konvergenz wird erhöht.
                </p>
            </section>
        </section>
    </main>
</body>
</html>